)
model
}
model <- build_model()
model %>% summary()
#train the model
# Display training progress by printing a single dot for each completed epoch.
print_dot_callback <- callback_lambda(
on_epoch_end = function(epoch, logs) {
if (epoch %% 80 == 0) cat("\n")
cat(".")
}
)
epochs <- 500
# Fit the model and store training stats
history <- model %>% fit(
train_data,
train_labels,
epochs = epochs,
validation_split = 0.2,
verbose = 0,
callbacks = list(print_dot_callback)
)
library(ggplot2)
plot(history, metrics = "mean_absolute_error", smooth = FALSE) +
coord_cartesian(ylim = c(0, 5))
# The patience parameter is the amount of epochs to check for improvement.
early_stop <- callback_early_stopping(monitor = "val_loss", patience = 20)
model <- build_model()
history <- model %>% fit(
train_data,
train_labels,
epochs = epochs,
validation_split = 0.2,
verbose = 0,
callbacks = list(early_stop, print_dot_callback)
)
plot(history, metrics = "mean_absolute_error", smooth = FALSE) +
coord_cartesian(xlim = c(0, 150), ylim = c(0, 5))
c(loss, mae) %<-% (model %>% evaluate(test_data, test_labels, verbose = 0))
paste0("Mean absolute error on test set: $", sprintf("%.2f", mae * 1000))
test_predictions <- model %>% predict(test_data)
test_predictions[ , 1]
library(caret)
library(rpart.plot)
#importing the dataset
dataset=read.csv("/home/anjana/Downloads/retinopathy.csv")
intrain=createDataPartition(y=dataset$risk,p=0.7,list=FALSE)
c(train_data, train_labels) <- dataset[intrain,]
df=read.csv("/home/anjana/anjana/PYTHON/tensor/boston.csv")
dataset=read.csv("/home/anjana/anjana/PYTHON/tensor/boston.csv")
intrain=createDataPartition(y=dataset$risk,p=0.7,list=FALSE)
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
source('~/anjana/r/tensor_boston.r')
runApp('anjana/r/sds')
df=data.frame(x,y)
df
df=as.data.frame(x,y)
runApp('anjana/r/sds')
boston_housing <- dataset_boston_housing()
head(boston_housing)
names(boston_housing)
library(keras)
df=read.csv("/home/anjana/anjana/PYTHON/tensor/boston.csv")
boston_housing <- dataset_boston_housing()
c(train_data, train_labels) %<-% boston_housing$train
c(test_data, test_labels) %<-% boston_housing$test
#Examples and features
paste0("Training entries: ", length(train_data), ", labels: ", length(train_labels))
library(tibble)
column_names <- c('CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE',
'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT')
train_df <- as_tibble(train_data)
colnames(train_df) <- column_names
train_df
Labels
train_labels[1:10] # Display first 10 entries
#Normalize features
# Test data is *not* used when calculating the mean and std.
# Normalize training data
train_data <- scale(train_data)
# Use means and standard deviations from training set to normalize test set
col_means_train <- attr(train_data, "scaled:center")
col_stddevs_train <- attr(train_data, "scaled:scale")
test_data <- scale(test_data, center = col_means_train, scale = col_stddevs_train)
train_data[1, ] # First training sample, normalized
#Create the model
build_model <- function() {
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu",
input_shape = dim(train_data)[2]) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 1)
model %>% compile(
loss = "mse",
optimizer = optimizer_rmsprop(),
metrics = list("mean_absolute_error")
)
model
}
model <- build_model()
model %>% summary()
#train the model
# Display training progress by printing a single dot for each completed epoch.
print_dot_callback <- callback_lambda(
on_epoch_end = function(epoch, logs) {
if (epoch %% 80 == 0) cat("\n")
cat(".")
}
)
epochs <- 500
# Fit the model and store training stats
history <- model %>% fit(
train_data,
train_labels,
epochs = epochs,
validation_split = 0.2,
verbose = 0,
callbacks = list(print_dot_callback)
)
library(ggplot2)
plot(history, metrics = "mean_absolute_error", smooth = FALSE) +
coord_cartesian(ylim = c(0, 5))
# The patience parameter is the amount of epochs to check for improvement.
early_stop <- callback_early_stopping(monitor = "val_loss", patience = 20)
model <- build_model()
history <- model %>% fit(
train_data,
train_labels,
epochs = epochs,
validation_split = 0.2,
verbose = 0,
callbacks = list(early_stop, print_dot_callback)
)
plot(history, metrics = "mean_absolute_error", smooth = FALSE) +
coord_cartesian(xlim = c(0, 150), ylim = c(0, 5))
c(loss, mae) %<-% (model %>% evaluate(test_data, test_labels, verbose = 0))
paste0("Mean absolute error on test set: $", sprintf("%.2f", mae * 1000))
test_predictions <- model %>% predict(test_data)
test_predictions[ , 1]
runApp('anjana/r/sds')
boston_housing <- dataset_boston_housing()
names(boston_housing)
names(train)
names(train_data)
train
boston_housing$train
c(train_data, train_labels) <-boston_housing$train
c(train_data, train_labels) =boston_housing$train
c(train_data, train_labels) %<-% x
c(test_data, test_labels) %<-% y
train_data=x[train_split,]
train_split=createDataPartition(x,p=0.7,list = FALSE)
train_data=x[train_split,]
test_data=x[-train_split,]
dataset
dataset1=read.csv("/home/anjana/anjana/PYTHON/tensor/boston.csv")
intrain=createDataPartition(y,p=0.7,list=FALSE)
training=dataset[intrain,]
testing=dataset[-intrain,]
dataset
training_s=createDataPartition(y=x,p=0.7,list = FALSE)
train_data_s=x[training_s]
test_data_s=x[training_s]
c(test_data, test_labels) %<-% boston_housing$test
test_data
names(test_data)
train_labels
training_s=createDataPartition(y=x,p=0.7,list = FALSE)
train_data_s=x[training_s,]
training_s=createDataPartition(y=x,p=0.7,list = FALSE)
train_data_s=x[training_s]
train_data_s
x<-c(train_data1,train_labels1)
y<-c(test_data1,test_labels1)
training_s=createDataPartition(y=x,p=0.7,list = FALSE)
train_data_s=x[training_s]
test_data_s=x[training_s]
labels=createDataPartition(y=y,p=0.7,list = FALSE)
train_lab_s=y[labels]
runApp('anjana/r/sds')
class
class(train_data_s)
dim(train_data_s)
class(x)
dim(x)
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
source('~/anjana/r/tensor_boston.r')
source('~/anjana/r/tensor_boston.r')
source('~/anjana/r/tensor_boston.r')
source('~/anjana/r/tensor_boston.r')
source('~/anjana/r/tensor_boston.r')
source('~/anjana/r/tensor_boston.r')
source('~/anjana/r/tensor_boston.r')
source('~/anjana/r/tensor_boston.r')
source('~/anjana/r/tensor_boston.r')
library(tensorflow)
library(keras)
df=read.csv("/home/anjana/anjana/PYTHON/tensor/boston.csv")
set.seed(100)
train_test_split <- initial_split(df, prop = 0.8)
train_test_split
train_tbl <- training(train_test_split)
test_tbl  <- testing(train_test_split)
train_tbl <- training(train_test_split)
source('~/anjana/r/tensor_boston.r')
source('~/anjana/r/tensor_boston.r')
source('~/anjana/r/tensor_boston.r')
train_test_split <- initial_split(df, prop = 0.8)
train_test_split
train_tbl <- training(train_test_split)
test_tbl  <- testing(train_test_split)
train_tbl
head(train_tbl)
dim(train_tbl)
head(test_tbl)
source('~/anjana/r/tensor_boston.r')
source('~/anjana/r/tensor_boston.r')
shiny::runApp('anjana/r/sds')
training=as.data.frame(df_sel())
# Select columns to print ----
df_sel <- reactive({
req(input$select_var)
df_sel <- df() %>% select(input$select_var)
})
df_sel_tar <- reactive({
req(input$select_var_tar)
df_sel_tar <- df() %>% select(input$select_var_tar)
})
training=as.data.frame(df_sel())
runApp('anjana/r/sds')
train_test_split
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
pkgs <- c("keras", "lime", "tidyquant", "rsample", "recipes", "yardstick", "corrr")
install.packages(pkgs)
install.packages(pkgs)
shiny::runApp('anjana/r/sds')
runApp('anjana/r/example')
runApp('anjana/r/example')
runApp('anjana/r/example')
runApp('anjana/r/example')
runApp('anjana/r/example')
features=as.data.frame(df_sel())
# Select columns to print ----
df_sel <- reactive({
req(input$select_var)
df_sel <- df() %>% select(input$select_var)
})
df_sel_tar <- reactive({
req(input$select_var_tar)
df_sel_tar <- df() %>% select(input$select_var_tar)
})
output$summary<-renderPrint({
if(input$disp=="head"){
summary(df_sel())
}
else{
df_sel()
}
})
output$summary_target<-renderPrint({
if(input$disp=="head"){
summary(df_sel_tar())
}
else{
df_sel_tar()
}
})
# Print data table ----
output$rendered_file <- DT::renderDataTable({
if(input$disp == "head") {
head(df_sel())
}
else {
df_sel()
}
})
output$rendered_file1 <- DT::renderDataTable({
if(input$disp == "head") {
head(df_sel_tar())
}
else {
df_sel_tar()
}
})
set.seed(1000)
observe({
features=as.data.frame(df_sel())
labels=df_sel_tar()
df=data.frame(features,labels)
train_test_split <- initial_split(features, prop = 0.8)
train_data_bos <- data.matrix(training(train_test_split))
test_data_bos  <- data.matrix(testing(train_test_split))
label_split<-initial_split(labels,prop = 0.8)
train_lab_bos<- data.matrix(training(label_split))
test_lab_bos <- data.matrix(testing(label_split))
train_dataa <- scale(train_data)
build_model <- function() {
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu",
input_shape = dim(train_data)[2]) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 1)
model %>% compile(
loss = "mse",
optimizer = optimizer_rmsprop(),
metrics = list("mean_absolute_error")
)
model
}
model <- build_model()
# model %>% summary()
#train the model
# Display training progress by printing a single dot for each completed epoch.
print_dot_callback <- callback_lambda(
on_epoch_end = function(epoch, logs) {
if (epoch %% 80 == 0) cat("\n")
cat(".")
}
)
epochs <- 500
history <- model %>% fit(
train_data_bos,
train_lab_bos,
epochs = epochs,
validation_split = 0.2,
verbose = 0,
callbacks = list(print_dot_callback)
)
observeEvent(input$rpart,{
output$unseen<-renderPrint({
return(class(train_data_bos))
})
})
})
features=as.data.frame(df_sel())
labels=df_sel_tar()
df=data.frame(features,labels)
train_test_split <- initial_split(features, prop = 0.8)
train_data_bos <- data.matrix(training(train_test_split))
test_data_bos  <- data.matrix(testing(train_test_split))
label_split<-initial_split(labels,prop = 0.8)
train_lab_bos<- data.matrix(training(label_split))
test_lab_bos <- data.matrix(testing(label_split))
train_dataa <- scale(train_data)
shiny::runApp('anjana/r/sds')
#importing the dataset
dataset=read.csv("/home/anjana/anjana/PYTHON/tensor/boston.csv")
#dataset=read.csv("/home/anjana/Downloads/retinopathy.csv")
#test_demo=read.csv("/home/anjana/Desktop/test_demo.csv")
head(dataset)
is.na(dataset)
library(caret)
library(rpart.plot)
intrain=createDataPartition(y=dataset$MV,p=0.7,list=FALSE)
training=dataset[intrain,]
testing=dataset[-intrain,]
class(training)
head(training)
head(testing)
features=as.data.frame(df_sel())
labels=df_sel_tar()
# Select columns to print ----
df_sel <- reactive({
req(input$select_var)
df_sel <- df() %>% select(input$select_var)
})
df_sel_tar <- reactive({
req(input$select_var_tar)
df_sel_tar <- df() %>% select(input$select_var_tar)
})
features=as.data.frame(df_sel())
labels=df_sel_tar()
df=data.frame(features,labels)
runApp('anjana/r/sds')
runApp('anjana/r/sds')
library("randomForest")
install.packages("randomForest")
runApp('anjana/r/sds')
library(heatmaply)
install.packages("heatmaply")
library(heatmaply)
runApp('anjana/r/sds')
install.pacl
install.packages("randomForest")
library("shiny")
library("randomForest")
library("randomForest")
runApp('anjana/r/sds')
library("ggplot2")
library(corrplot)
library(rpart)
rpart.plot
library(rpart.plot)
library(devtools)
library(corrplot)
library(rpart)
library(svm)
pkg.list = available.packages()
download.packages(pkgs = pkg.list, destdir = "C:\\MyRPackages")
download.packages(pkgs = pkg.list, destdir = "/home/anjana/R/x86_64-pc-linux-gnu-library/3.4")
library(randomForest)
library(randomForest)
library(lime)
install.packages("lime")
library(lime_0.4.0.tar.gz)
install.packages("lime")
install.packages("lime",dependencies = TRUE)
shiny::runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
library(recipes)
library(recipes)
library(yardstick)
library(yardstick)
library(tidyquant)
install.packages("tidyquant")
library(tidyquant)
library(tidyquant)
library(tidyquant)
install.packages("magic")
install.packages("magic")
install.packages("magic")
library(magic)
library(magic)
install.packages("tree")
library("tree")
library(rattle)					# Fancy tree plot
install.packages("rattle")
library(RColorBrewer)				# Color selection for fancy tree plot
library(partykit)				# Convert rpart object to BinaryTree
install.packages("party")
library("party")
library("party")
library(partykit)				# Convert rpart object to BinaryTree
install.packages("partykit")
library(partykit)				# Convert rpart object to BinaryTree
library(partykit)				# Convert rpart object to BinaryTree
library(neuralnet) # you will need this to do neural network
install.packages("neuralnet")
library(neuralnet) # you will need this to do neural network
library(xtable) # good to have
library(shiny, dependencies=TRUE)
library(shinythemes
)
shiny::runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/example2')
runApp('anjana/r/example2')
runApp('anjana/r/example2')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/example2')
runApp('anjana/r/example')
runApp('anjana/r/example')
runApp('anjana/r/example')
runApp('anjana/r/sds')
runApp('anjana/r/example2')
runApp('anjana/r/example2')
runApp('anjana/r/sds')
runApp('anjana/r/example2')
runApp('anjana/r/example2')
runApp('anjana/r/example2')
runApp('anjana/r/example2')
runApp('anjana/r/example')
runApp('anjana/r/example2')
install.packages("shinyWidgets")
runApp('anjana/r/sds')
runApp('anjana/r/example2')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/example2')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
install.packages("dplyr")
install.packages("dplyr")
runApp('anjana/r/sds')
runApp('anjana/r/example2')
runApp('anjana/r/sds')
runApp('anjana/r/example2')
runApp('anjana/r/example2')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
runApp('anjana/r/example2')
runApp('anjana/r/example2')
runApp('anjana/r/sds')
runApp('anjana/r/sds')
library(dplyr)
runApp('anjana/r/sds')
runApp('anjana/r/sds')
